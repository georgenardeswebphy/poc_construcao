{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5250c-3625-4e1d-a46a-0f259978d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os \n",
    "import glob\n",
    "import random\n",
    "import tensorflow.keras as keras\n",
    "import keras.layers as layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a963055-e3e7-408b-9115-c17230fb7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_W = 224\n",
    "IMG_H = 224\n",
    "S = 14 # number of grid cells in  the output\n",
    "D = 5 # depth of each grid cells\n",
    "NUM_VAL_SAMPLES = 128\n",
    "\n",
    "# diretório a ser salvo\n",
    "tfrecords_dir = \"tfrecords_detection\"\n",
    "\n",
    "#diretório de labels\n",
    "LABEL_DIR =  r\"../datasetbuilding/labels/*/*\" \n",
    "\n",
    "\n",
    "annotations = glob.glob(LABEL_DIR)\n",
    "random.shuffle(annotations)\n",
    "print(\"total de imagens: \", len(annotations))\n",
    "\n",
    "train_annotations = annotations[NUM_VAL_SAMPLES:]\n",
    "val_annotations = annotations[:NUM_VAL_SAMPLES]\n",
    "print(train_annotations[0:10])\n",
    "\n",
    "\n",
    "#num_samples is the number of data samples on each TFRecord file. (TEM Q SER MENORIGUAL DO Q O NUMERO DE IMAGENS)\n",
    "#num_tfrecords is total number of TFRecords that we will create.\n",
    "num_samples_train = 8*1024\n",
    "num_tfrecords_train = len(train_annotations) // num_samples_train\n",
    "if len(train_annotations) % num_samples_train:\n",
    "    num_tfrecords_train += 1  # add one record if there are any remaining samples\n",
    "if len(train_annotations) < num_samples_train:\n",
    "    print(\"Erro no tamanho do TFRecord\")\n",
    "    \n",
    "    \n",
    "num_samples_val = NUM_VAL_SAMPLES\n",
    "num_tfrecords_val = len(val_annotations) // num_samples_val\n",
    "if len(val_annotations) % num_samples_val:\n",
    "    num_tfrecords_val += 1  # add one record if there are any remaining samples\n",
    "    \n",
    "\n",
    "if not os.path.exists(tfrecords_dir+\"\\\\train\"):    \n",
    "    os.makedirs(tfrecords_dir+\"\\\\train\")  # creating TFRecords output folder    \n",
    "\n",
    "if not os.path.exists(tfrecords_dir+\"\\\\val\"):\n",
    "    os.makedirs(tfrecords_dir+\"\\\\val\")  # creating TFRecords output folder    \n",
    "    \n",
    "print(\"num_tfrecords for train {}\".format(num_tfrecords_train))\n",
    "print(\"num_tfrecords for val {}\".format(num_tfrecords_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e59f7c2-5108-48fb-b2d0-c2356e3b753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def bbox_str_to_float(bbox_str):\n",
    "    return [float(bbox_str[0]), float(bbox_str[1]), float(bbox_str[2]), float(bbox_str[3]), float(bbox_str[4])]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" converte centroid relativo a imagem para centroid relativo da grid \"\"\"\n",
    "def img_to_grid_relative(bbox, S):\n",
    "    grid_x = int(bbox[0]*S)\n",
    "    grid_y = int(bbox[1]*S)\n",
    "\n",
    "    x_grid_relative = np.around(bbox[0]*S - grid_x, 5)\n",
    "    y_grid_relative = np.around(bbox[1]*S - grid_y, 5)\n",
    "\n",
    "    return [x_grid_relative, y_grid_relative]\n",
    "\n",
    "\n",
    "def labelfile_to_tensor(label_file_name, S, D):\n",
    "    output_label_map = np.zeros((S, S, D))\n",
    "    with open(label_file_name, 'r') as label_file:        \n",
    "\n",
    "        for line in label_file.readlines():                \n",
    "            bbox_str = line.replace(\"\\n\", \"\").split(\" \")\n",
    "            bbox = bbox_str_to_float(bbox_str) # BBOX CONTAINS OBJECTNESS ON THE FIRST POSITION\n",
    "\n",
    "            # converte posição relativa para output S,S\n",
    "            grid_x = int(bbox[1]*S)\n",
    "            grid_y = int(bbox[2]*S)\n",
    "\n",
    "            xy_grid_relative = img_to_grid_relative(bbox[1:], S)        \n",
    "            #print(\"grid [{},{}], imgrel[{},{}], offset[{},{}] \".format(grid_x,grid_y, bbox[1], bbox[2], xy_grid_relative[0],xy_grid_relative[1]))        \n",
    "            bbox[1] = xy_grid_relative[0]\n",
    "            bbox[2] = xy_grid_relative[1]                \n",
    "\n",
    "            if output_label_map[grid_x, grid_y, 0] == 1:\n",
    "                print(\"Ja inserido objeto na célula {},{}\".format(grid_x, grid_y))\n",
    "\n",
    "            output_label_map[grid_x, grid_y] = np.asarray([1]+bbox[1:])\n",
    "\n",
    "        return output_label_map\n",
    "\n",
    "\n",
    "\n",
    "def image_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(value=[tf.io.encode_png(value).numpy()])\n",
    "    )\n",
    "\n",
    "def output_tensor(value):    \n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n",
    "\n",
    "\n",
    "def float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def float_feature_list(value):\n",
    "    \"\"\"Returns a list of float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def create_example(image, path, yolo_boxes, S, D):\n",
    "    feature = {\n",
    "        \"image\": image_feature(image),\n",
    "        \"path\": bytes_feature(path),        \n",
    "        \"S\": int64_feature(S), # output grid cells\n",
    "        \"D\": int64_feature(D), # depth of each grid cell\n",
    "        \"yolo_boxes\": float_feature_list(yolo_boxes),                \n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"path\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"S\": tf.io.FixedLenFeature([], tf.int64), # output grid cells\n",
    "        \"D\": tf.io.FixedLenFeature([], tf.int64), # depth of each grid cell\n",
    "        \"yolo_boxes\": tf.io.FixedLenFeature([S*S*D], tf.float32), # S*S*D\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    example[\"image\"] = tf.io.decode_png(example[\"image\"], channels=3)    \n",
    "    \n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cfe298-1093-42e7-b86e-2d6217466215",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LABEL_DIR = LABEL_DIR.replace(\"/*\", \"\")\n",
    "for tfrec_num in range(num_tfrecords_train):\n",
    "    samples = annotations[(tfrec_num * num_samples_train) : ((tfrec_num + 1) * num_samples_train)]\n",
    "\n",
    "    with tf.io.TFRecordWriter(tfrecords_dir + \"/train/file_%.2i-%i.tfrec\" % (tfrec_num, len(samples))) as writer:\n",
    "        for sample in samples:\n",
    "            obj_class = sample.split(\"\\\\\")[-2]\n",
    "            obj_name = sample.split(\"\\\\\")[-1].replace(\".txt\", \"\")\n",
    "            \n",
    "            image_path = f\"../dataset/imagens/{obj_class}/{obj_name}.png\"      \n",
    "            #print(image_path)\n",
    "            image = tf.io.decode_png(tf.io.read_file(image_path))\n",
    "            \n",
    "            label_file_name = f\"{LABEL_DIR}/{obj_class}/{obj_name}.txt\"            \n",
    "            output_label_tensor =  list(labelfile_to_tensor(label_file_name, S, D).ravel().astype('float32'))\n",
    "                                    \n",
    "            example = create_example(image, image_path, output_label_tensor, S, D)         \n",
    "            writer.write(example.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c054d9-7439-472f-8c60-78b1b9f61716",
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "for tfrec_num in range(num_tfrecords_val):\n",
    "    samples = annotations[(tfrec_num * num_samples_val) : ((tfrec_num + 1) * num_samples_val)]\n",
    "\n",
    "    with tf.io.TFRecordWriter(tfrecords_dir + \"/val/file_%.2i-%i.tfrec\" % (tfrec_num, len(samples))) as writer:\n",
    "        for sample in samples:\n",
    "            obj_class = sample.split(\"\\\\\")[-2]\n",
    "            obj_name = sample.split(\"\\\\\")[-1].replace(\".txt\", \"\")\n",
    "            \n",
    "            image_path = f\"../dataset/imagens/{obj_class}/{obj_name}.png\"            \n",
    "            image = tf.io.decode_png(tf.io.read_file(image_path))\n",
    "            \n",
    "            label_file_name = f\"{LABEL_DIR}/{obj_class}/{obj_name}.txt\"            \n",
    "            output_label_tensor =  list(labelfile_to_tensor(label_file_name, S, D).ravel().astype('float32'))\n",
    "                                    \n",
    "            example = create_example(image, image_path, output_label_tensor, S, D)         \n",
    "            writer.write(example.SerializeToString())          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c2d40f-4ec9-47b0-aad7-3889ecfd7a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
